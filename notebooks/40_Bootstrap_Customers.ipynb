{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "title": "Bootstrap Customers"
  },
  "cells": [
    {
      "id": "bd1d3b1b",
      "cell_type": "markdown",
      "source": "# 40 \u2013 Bootstrap Customers from PaySim (Optional)",
      "metadata": {}
    },
    {
      "id": "168b9277",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from pyspark.sql import functions as F, Window\nRAW = VOLUME_URI_RAW\np = spark.read.csv(RAW + \"/paysim/paysim_small.csv\", header=True, inferSchema=True)\nw = Window.orderBy(\"nameOrig\")\ncustomers = (p.select(F.col(\"nameOrig\").alias(\"customer_id\")).distinct()\n               .withColumn(\"name\", F.concat(F.lit(\"Cust_\"), F.row_number().over(w)))\n               .withColumn(\"email\", F.concat(F.col(\"name\"), F.lit(\"@example.com\")))\n               .withColumn(\"dob\", F.to_date(F.lit(\"1985-01-01\")))\n               .withColumn(\"country\", F.lit(\"IN\"))\n               .withColumn(\"national_id\", F.concat(F.lit(\"IN-\"), F.monotonically_increasing_id()))\n               .withColumn(\"pep_flag\", (F.rand() < 0.02).cast(\"boolean\")))\n\nout = RAW + \"/customers/customers.csv\"\ncustomers.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(out)\nprint(\"Wrote customers to\", out)",
      "outputs": []
    }
  ]
}